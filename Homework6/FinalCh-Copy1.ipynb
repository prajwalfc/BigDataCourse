{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "def createIndex(shapefile):\n",
    "    import rtree\n",
    "    import fiona.crs\n",
    "    import geopandas as gpd\n",
    "    zones = gpd.read_file(shapefile).to_crs(fiona.crs.from_epsg(4326))\n",
    "    index = rtree.Rtree()\n",
    "    for idx,geometry in enumerate(zones.geometry):\n",
    "        index.insert(idx, geometry.bounds)\n",
    "    return (index, zones)\n",
    "\n",
    "def findZone(p, index, zones):\n",
    "    match = index.intersection((p.x, p.y, p.x, p.y))\n",
    "    for idx in match:\n",
    "        if zones.geometry[idx].contains(p):\n",
    "            return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDrugsFromFileToSets(fn1,fn2):\n",
    "    import re\n",
    "    w=set()\n",
    "    with open(fn1) as reader:\n",
    "        rows = reader.read()\n",
    "        for row in rows.split(\"\\n\"):\n",
    "            w.add(\" \".join(re.split(r'\\W+',row)))\n",
    "    with open(fn2) as reader:\n",
    "        rows = reader.read()\n",
    "        for row in rows.split(\"\\n\"):\n",
    "            w.add(\" \".join(re.split(r'\\W+',row)))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterDrugs(tweets):\n",
    "    import re\n",
    "    if tweets[1]==0:\n",
    "        return False\n",
    "    drugs_set = getDrugsFromFileToSets('drug_illegal.txt','drug_sched2.txt')\n",
    "    lst = re.split(r'\\W+',tweets[2])\n",
    "    lst = list(filter(lambda x:x!=\"\",lst))\n",
    "    i=0\n",
    "    lst1=[]\n",
    "    for word1 in lst:\n",
    "        j=i+1\n",
    "        temp =word1\n",
    "        if(temp in drugs_set):\n",
    "            return True\n",
    "        for word2 in lst[j:]:\n",
    "            temp = temp+\" \"+word2\n",
    "            if(temp in drugs_set):\n",
    "                return True\n",
    "        i=i+1\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(tweetData):\n",
    "    import pyproj\n",
    "    import shapely.geometry as geom\n",
    "    proj = pyproj.Proj(init=\"epsg:4326\", preserve_units=False)\n",
    "    main_index , main_zone = createIndex('500cities_tracts.geojson')\n",
    "    city_index = None\n",
    "    for tweet in tweetData:\n",
    "        tweet_split = tweet.split('|')\n",
    "        try:\n",
    "            x = float(tweet_split[2])\n",
    "            y = float(tweet_split[1])\n",
    "            point = geom.Point((x,y))\n",
    "            city_index = findZone(point,main_index,main_zone)\n",
    "        except:\n",
    "            pass\n",
    "        if not city_index:\n",
    "            pass\n",
    "            #print(tweet_split[0])\n",
    "        else:\n",
    "            yield(main_zone['plctract10'][city_index],main_zone['plctrpop10'][city_index],tweet_split[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(data):\n",
    "    return (data[0],data[1]),1\n",
    "def normalizer(data):\n",
    "    return data[0][0],float(data[1])/float(data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    #sc = SparkContext()\n",
    "    sc.textFile('/data/share/bdm/tweets-100m.csv').mapPartitions(partition).filter(filterDrugs).map(mapper).reduceByKey(lambda x,y:x+y).map(normalizer).sortBy(lambda x:x[0]).saveAsTextFile(\"final005\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
