{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4 - MapReduce\n",
    "\n",
    "In this lab, we are practicing the MapReduce programming paradigm. \n",
    "\n",
    "We will complete the tasks using the accompanied *mapreduce* package (as **mapreduce.py**) and MRJob. Please download the **mapreduce.py** file from our online class resource page, and place it in the same folder with your notebook.\n",
    "\n",
    "Please also install MRJob through **pip install mrjob**.\n",
    "\n",
    "For each invocation of an MapREduce job (with mr.run()), you are expected to supply a mapper, a reducer and/or a combiner as needed. Below are sample usage of the package:\n",
    "\n",
    "```python\n",
    "    # Run on input1 using your mapper1 and reducer1 function\n",
    "    output = list(mr.run(input1, mapper1, reducer1))\n",
    "\n",
    "    # Run on input2 using only your mapper2, no reduce phase\n",
    "    output = list(mr.run(enumerate(input2), mapper2, combiner2))\n",
    "    \n",
    "    # Run on input3 using 2 nested MapReduce jobs\n",
    "    output = mr.run(mr.run(input3, mapper3, reducer3), mapper4)\n",
    "```\n",
    "    \n",
    "Please note that the input must be an iteratable of **key/value pairs**. If your input data does not have a key, you can simply add a null or index key through **enumerator(input)**. The output of the mr.run() is always a **generator**. You have to cast it to a list if you'd like to view, index or print it out.\n",
    "\n",
    "The tasks below also include those that are in Homework 2, but we're using MapReduce instead of Python's general Higher Order Functions.\n",
    "\n",
    "You will need **book.txt** and **citibike.csv** file from the class resource page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import mapreduce as mr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0\n",
    "\n",
    "Here is another concrete example on \"Word Count\" using the package. Assuming we have a text file named *book.txt*. Our task is to count the frequency of words in this document, and print the top 10. For illustration purposes, we use only the first 1000 lines of the book for counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 360),\n",
       " ('of', 326),\n",
       " ('and', 246),\n",
       " ('a', 169),\n",
       " ('or', 161),\n",
       " ('to', 101),\n",
       " ('with', 100),\n",
       " ('in', 88),\n",
       " ('on', 67),\n",
       " ('as', 56),\n",
       " ('are', 52),\n",
       " ('coins', 46),\n",
       " ('The', 45),\n",
       " ('which', 45),\n",
       " ('is', 42),\n",
       " ('be', 34),\n",
       " ('have', 34),\n",
       " ('other', 34),\n",
       " ('that', 33),\n",
       " ('_Obverse_,', 32),\n",
       " ('by', 31),\n",
       " ('_Reverse_,', 30),\n",
       " ('been', 30),\n",
       " ('from', 29),\n",
       " ('name', 25),\n",
       " ('some', 25),\n",
       " ('an', 23),\n",
       " ('letters', 23),\n",
       " ('at', 22),\n",
       " ('but', 20),\n",
       " ('one', 20),\n",
       " ('more', 18),\n",
       " ('REX', 17),\n",
       " ('has', 17),\n",
       " ('two', 17),\n",
       " ('was', 17),\n",
       " ('[Illustration]', 16),\n",
       " ('horse', 16),\n",
       " ('it', 16),\n",
       " ('may', 16),\n",
       " ('moneyer’s', 16),\n",
       " ('those', 16),\n",
       " ('A', 15),\n",
       " ('for', 15),\n",
       " ('bust', 14),\n",
       " ('this', 14),\n",
       " ('others,', 13),\n",
       " ('were', 13),\n",
       " ('country', 12),\n",
       " ('cross', 12),\n",
       " ('etc.', 12),\n",
       " ('not', 12),\n",
       " ('about', 11),\n",
       " ('horse,', 11),\n",
       " ('name,', 11),\n",
       " ('our', 11),\n",
       " ('upon', 11),\n",
       " ('\"', 10),\n",
       " ('_reverse_,', 10),\n",
       " ('between', 10),\n",
       " ('first', 10),\n",
       " ('had', 10),\n",
       " ('less', 10),\n",
       " ('part', 10),\n",
       " ('present', 10),\n",
       " ('rude', 10),\n",
       " ('without', 10),\n",
       " ('}', 10),\n",
       " ('OF', 9),\n",
       " ('being', 9),\n",
       " ('coin', 9),\n",
       " ('coins,', 9),\n",
       " ('disjointed', 9),\n",
       " ('etc.,', 9),\n",
       " ('its', 9),\n",
       " ('most', 9),\n",
       " ('no', 9),\n",
       " ('their', 9),\n",
       " ('who', 9),\n",
       " ('within', 9),\n",
       " ('CVNO.', 8),\n",
       " ('REX,', 8),\n",
       " ('any', 8),\n",
       " ('son', 8),\n",
       " ('struck', 8),\n",
       " ('type', 8),\n",
       " ('what', 8),\n",
       " ('winged', 8),\n",
       " ('(p.', 7),\n",
       " ('COM', 7),\n",
       " ('Coins', 7),\n",
       " ('One', 7),\n",
       " ('_obverse_', 7),\n",
       " ('above', 7),\n",
       " ('across', 7),\n",
       " ('beaded', 7),\n",
       " ('bearing', 7),\n",
       " ('considerable', 7),\n",
       " ('counties', 7),\n",
       " ('gold', 7),\n",
       " ('head', 7),\n",
       " ('his', 7),\n",
       " ('known', 7),\n",
       " ('known.', 7),\n",
       " ('lines', 7),\n",
       " ('number', 7),\n",
       " ('period', 7),\n",
       " ('some,', 7),\n",
       " ('there', 7),\n",
       " ('they', 7),\n",
       " ('types', 7),\n",
       " ('various', 7),\n",
       " ('very', 7),\n",
       " ('whose', 7),\n",
       " ('6,', 6),\n",
       " ('DISTRICT,', 6),\n",
       " ('F', 6),\n",
       " ('Fig.', 6),\n",
       " ('REX.', 6),\n",
       " ('Roman', 6),\n",
       " ('THE', 6),\n",
       " ('and,', 6),\n",
       " ('bear', 6),\n",
       " ('before', 6),\n",
       " ('comprising', 6),\n",
       " ('early', 6),\n",
       " ('found', 6),\n",
       " ('horseman', 6),\n",
       " ('inscribed', 6),\n",
       " ('limbs', 6),\n",
       " ('made', 6),\n",
       " ('of--', 6),\n",
       " ('others', 6),\n",
       " ('parts', 6),\n",
       " ('same', 6),\n",
       " ('these', 6),\n",
       " ('three', 6),\n",
       " ('uninscribed', 6),\n",
       " ('well', 6),\n",
       " ('*', 5),\n",
       " ('A.D.', 5),\n",
       " ('B.C.', 5),\n",
       " ('British', 5),\n",
       " ('F;', 5),\n",
       " ('It', 5),\n",
       " ('Mr.', 5),\n",
       " ('_obverse_,', 5),\n",
       " ('almost', 5),\n",
       " ('also', 5),\n",
       " ('art', 5),\n",
       " ('became', 5),\n",
       " ('certain', 5),\n",
       " ('contemporary', 5),\n",
       " ('cross,', 5),\n",
       " ('each', 5),\n",
       " ('earliest', 5),\n",
       " ('etc.;', 5),\n",
       " ('general', 5),\n",
       " ('imitations', 5),\n",
       " ('mintage', 5),\n",
       " ('money', 5),\n",
       " ('place', 5),\n",
       " ('side', 5),\n",
       " ('so', 5),\n",
       " ('varieties', 5),\n",
       " ('(?)', 4),\n",
       " ('C', 4),\n",
       " ('CEOLVVLF', 4),\n",
       " ('COINS', 4),\n",
       " ('COMMI', 4),\n",
       " ('CVN.', 4),\n",
       " ('English', 4),\n",
       " ('Greek', 4),\n",
       " ('RICON', 4),\n",
       " ('Surrey,', 4),\n",
       " ('TASCI', 4),\n",
       " ('Tasciovanus', 4),\n",
       " ('_circa_', 4),\n",
       " ('_reverse_', 4),\n",
       " ('all', 4),\n",
       " ('among', 4),\n",
       " ('appear', 4),\n",
       " ('attempt', 4),\n",
       " ('attributed', 4),\n",
       " ('bust,', 4),\n",
       " ('character', 4),\n",
       " ('classed', 4),\n",
       " ('coast', 4),\n",
       " ('cruciform', 4),\n",
       " ('date.', 4),\n",
       " ('device', 4),\n",
       " ('engraved', 4),\n",
       " ('examples', 4),\n",
       " ('fifty', 4),\n",
       " ('head;', 4),\n",
       " ('here', 4),\n",
       " ('inner', 4),\n",
       " ('into', 4),\n",
       " ('king', 4),\n",
       " ('laureated', 4),\n",
       " ('letter', 4),\n",
       " ('much', 4),\n",
       " ('name.', 4),\n",
       " ('names', 4),\n",
       " ('over', 4),\n",
       " ('profile', 4),\n",
       " ('said', 4),\n",
       " ('seem', 4),\n",
       " ('seems', 4),\n",
       " ('show', 4),\n",
       " ('silver', 4),\n",
       " ('supposed', 4),\n",
       " ('tablet', 4),\n",
       " ('than', 4),\n",
       " ('them', 4),\n",
       " ('therefore,', 4),\n",
       " ('time', 4),\n",
       " ('town', 4),\n",
       " ('tribes', 4),\n",
       " ('under', 4),\n",
       " ('usually', 4),\n",
       " ('variety', 4),\n",
       " ('word', 4),\n",
       " ('your', 4),\n",
       " ('(?).', 3),\n",
       " ('(and', 3),\n",
       " ('Among', 3),\n",
       " ('Anglo-Saxon', 3),\n",
       " ('BODVOC', 3),\n",
       " ('Berkshire.', 3),\n",
       " ('CVNOBELINVS.', 3),\n",
       " ('Celtic', 3),\n",
       " ('Commivs.', 3),\n",
       " ('D', 3),\n",
       " ('Devonshire.', 3),\n",
       " ('EPPI', 3),\n",
       " ('Evans,', 3),\n",
       " ('F.', 3),\n",
       " ('Hampshire,', 3),\n",
       " ('I', 3),\n",
       " ('I.,', 3),\n",
       " ('Iceni.', 3),\n",
       " ('Kent', 3),\n",
       " ('M,', 3),\n",
       " ('RE,', 3),\n",
       " ('Saxon', 3),\n",
       " ('Suffolk,', 3),\n",
       " ('Sussex,', 3),\n",
       " ('TASCIO', 3),\n",
       " ('TINC', 3),\n",
       " ('V.', 3),\n",
       " ('VERICA', 3),\n",
       " ('VIR;', 3),\n",
       " ('_KINGS', 3),\n",
       " ('_reverse_;', 3),\n",
       " ('_stater_', 3),\n",
       " ('after', 3),\n",
       " ('ancient', 3),\n",
       " ('angles', 3),\n",
       " ('another', 3),\n",
       " ('are,', 3),\n",
       " ('ascribed', 3),\n",
       " ('began', 3),\n",
       " ('below', 3),\n",
       " ('branch', 3),\n",
       " ('brother', 3),\n",
       " ('bust.', 3),\n",
       " ('can', 3),\n",
       " ('capital', 3),\n",
       " ('central', 3),\n",
       " ('chariot-wheel,', 3),\n",
       " ('circle,', 3),\n",
       " ('city', 3),\n",
       " ('class', 3),\n",
       " ('country;', 3),\n",
       " ('currency', 3),\n",
       " ('degree', 3),\n",
       " ('described', 3),\n",
       " ('device.', 3),\n",
       " ('different', 3),\n",
       " ('double', 3),\n",
       " ('during', 3),\n",
       " ('eagle', 3),\n",
       " ('engraved.', 3),\n",
       " ('evidently', 3),\n",
       " ('figure', 3),\n",
       " ('four', 3),\n",
       " ('front', 3),\n",
       " ('generally', 3),\n",
       " ('geographical', 3),\n",
       " ('gradual', 3),\n",
       " ('has,', 3),\n",
       " ('have,', 3),\n",
       " ('head,', 3),\n",
       " ('her', 3),\n",
       " ('him', 3),\n",
       " ('however,', 3),\n",
       " ('hundred', 3),\n",
       " ('imitation', 3),\n",
       " ('included', 3),\n",
       " ('knowledge', 3),\n",
       " ('known,', 3),\n",
       " ('laws', 3),\n",
       " ('localities', 3),\n",
       " ('looked', 3),\n",
       " ('moneyers’', 3),\n",
       " ('naturally,', 3),\n",
       " ('only', 3),\n",
       " ('ordinary', 3),\n",
       " ('original', 3),\n",
       " ('own', 3),\n",
       " ('referred', 3),\n",
       " ('reign', 3),\n",
       " ('right,', 3),\n",
       " ('rising', 3),\n",
       " ('serve', 3),\n",
       " ('several', 3),\n",
       " ('side,', 3),\n",
       " ('similar', 3),\n",
       " ('sons', 3),\n",
       " ('sunk', 3),\n",
       " ('tablet,', 3),\n",
       " ('tablet;', 3),\n",
       " ('thus', 3),\n",
       " ('two,', 3),\n",
       " ('uncertain', 3),\n",
       " ('use', 3),\n",
       " ('varieties.', 3),\n",
       " ('was,', 3),\n",
       " ('we', 3),\n",
       " ('yet', 3),\n",
       " ('(supposed', 2),\n",
       " ('***', 2),\n",
       " ('...', 2),\n",
       " ('...,', 2),\n",
       " ('1', 2),\n",
       " ('2', 2),\n",
       " ('24', 2),\n",
       " ('5', 2),\n",
       " ('A,', 2),\n",
       " ('AMMINVS.', 2),\n",
       " ('AN.', 2),\n",
       " ('ANCIENT', 2),\n",
       " ('AND', 2),\n",
       " ('ANDOCO;', 2),\n",
       " ('ANDOCO[MIVS]', 2),\n",
       " ('ANTED,', 2),\n",
       " ('AVN', 2),\n",
       " ('About', 2),\n",
       " ('Abp.', 2),\n",
       " ('And', 2),\n",
       " ('Another', 2),\n",
       " ('As', 2),\n",
       " ('B.C.,', 2),\n",
       " ('BALDRED,', 2),\n",
       " ('BELI.', 2),\n",
       " ('BEORHTRIC,', 2),\n",
       " ('BY', 2),\n",
       " ('Barclay', 2),\n",
       " ('Bedfordshire,', 2),\n",
       " ('Berks,', 2),\n",
       " ('Berkshire,', 2),\n",
       " ('Boadicea,', 2),\n",
       " ('Brigantes,', 2),\n",
       " ('Britons', 2),\n",
       " ('Britons,', 2),\n",
       " ('Buckinghamshire,', 2),\n",
       " ('But', 2),\n",
       " ('CA', 2),\n",
       " ('CAM.', 2),\n",
       " ('CAMVL.', 2),\n",
       " ('CANT.', 2),\n",
       " ('CATTI.', 2),\n",
       " ('CAV', 2),\n",
       " ('CIOLVVLF', 2),\n",
       " ('COMMIVS', 2),\n",
       " ('COMVX.', 2),\n",
       " ('CV', 2),\n",
       " ('CVDRED', 2),\n",
       " ('CVNO', 2),\n",
       " ('CVNOBELI.', 2),\n",
       " ('CVNOBELINI.', 2),\n",
       " ('CVNOBELINVS', 2),\n",
       " ('Cambridgeshire,', 2),\n",
       " ('Canterbury,', 2),\n",
       " ('Chapter', 2),\n",
       " ('Coins,', 2),\n",
       " ('Commius.', 2),\n",
       " ('Cunobeline.', 2),\n",
       " ('DVRO', 2),\n",
       " ('Derbyshire,', 2),\n",
       " ('Dorsetshire.', 2),\n",
       " ('E', 2),\n",
       " ('EADMUND,', 2),\n",
       " ('ECEN', 2),\n",
       " ('ENGLISH', 2),\n",
       " ('EPPI,', 2),\n",
       " ('EPPILLVS,', 2),\n",
       " ('ETHELWARD,', 2),\n",
       " ('Epaticcus,', 2),\n",
       " ('Evans', 2),\n",
       " ('F,', 2),\n",
       " ('From', 2),\n",
       " ('Gaul', 2),\n",
       " ('Gaul,', 2),\n",
       " ('Gaulish', 2),\n",
       " ('Gloucester,', 2),\n",
       " ('Great', 2),\n",
       " ('Gutenberg', 2),\n",
       " ('Hants,', 2),\n",
       " ('Head', 2),\n",
       " ('Hercules,', 2),\n",
       " ('Hertfordshire.', 2),\n",
       " ('Huntingdonshire,', 2),\n",
       " ('I.', 2),\n",
       " ('II.', 2),\n",
       " ('II.,', 2),\n",
       " ('INAM,', 2),\n",
       " ('INARA.', 2),\n",
       " ('INMA,', 2),\n",
       " ('In', 2),\n",
       " ('Irish', 2),\n",
       " ('Jewitt', 2),\n",
       " ('Lancashire,', 2),\n",
       " ('Leicestershire,', 2),\n",
       " ('Llewellynn', 2),\n",
       " ('M', 2),\n",
       " ('M.', 2),\n",
       " ('MV.', 2),\n",
       " ('Macedon,', 2),\n",
       " ('Massilia', 2),\n",
       " ('Mercia,', 2),\n",
       " ('Middlesex,', 2),\n",
       " ('Monmouthshire,', 2),\n",
       " ('Northamptonshire,', 2),\n",
       " ('Of', 2),\n",
       " ('Offa,', 2),\n",
       " ('On', 2),\n",
       " ('Other', 2),\n",
       " ('Oxfordshire', 2),\n",
       " ('P', 2),\n",
       " ('Pegasus,', 2),\n",
       " ('Pegasus;', 2),\n",
       " ('Philip', 2),\n",
       " ('Philippus', 2),\n",
       " ('Project', 2),\n",
       " ('R', 2),\n",
       " ('RE', 2),\n",
       " ('RX,', 2),\n",
       " ('Runic', 2),\n",
       " ('SEGO', 2),\n",
       " ('SVEI.', 2),\n",
       " ('Scotland.', 2),\n",
       " ('Sea.', 2),\n",
       " ('Some', 2),\n",
       " ('St.', 2),\n",
       " ('Staffordshire,', 2),\n",
       " ('T', 2),\n",
       " ('TASC', 2),\n",
       " ('TASC.', 2),\n",
       " ('TASCIA;', 2),\n",
       " ('TASCIO.', 2),\n",
       " ('TASCIOVANI.', 2),\n",
       " ('TIN;', 2),\n",
       " ('Tasciovanus,', 2),\n",
       " ('Tasciovanus.', 2),\n",
       " ('These', 2),\n",
       " ('This', 2),\n",
       " ('United', 2),\n",
       " ('VEP', 2),\n",
       " ('VEROS,', 2),\n",
       " ('VOSE[NOS]', 2),\n",
       " ('Verulamium,', 2),\n",
       " ('Victory', 2),\n",
       " ('West', 2),\n",
       " ('Wilts,', 2),\n",
       " ('[Illustration:', 2),\n",
       " ('_recorded_', 2),\n",
       " ('_sceat_', 2),\n",
       " ('above,', 2),\n",
       " ('accompanied', 2),\n",
       " ('accompaniments,', 2),\n",
       " ('according', 2),\n",
       " ('acquired', 2),\n",
       " ('additional', 2),\n",
       " ('adjacent', 2),\n",
       " ('already', 2),\n",
       " ('also,', 2),\n",
       " ('another,', 2),\n",
       " ('appropriated', 2),\n",
       " ('appropriation', 2),\n",
       " ('approximate', 2),\n",
       " ('arrangement', 2),\n",
       " ('assigned', 2),\n",
       " ('at.', 2),\n",
       " ('attempted', 2),\n",
       " ('back', 2),\n",
       " ('barbarous', 2),\n",
       " ('bearded', 2),\n",
       " ('bears', 2),\n",
       " ('becomes', 2),\n",
       " ('before,', 2),\n",
       " ('beneath', 2),\n",
       " ('beneath,', 2),\n",
       " ('biga,', 2),\n",
       " ('birth', 2),\n",
       " ('bull’s', 2),\n",
       " ('certainty', 2),\n",
       " ('certainty,', 2),\n",
       " ('characters,', 2),\n",
       " ('chariot-wheel', 2),\n",
       " ('chief', 2),\n",
       " ('circular', 2),\n",
       " ('civilization', 2),\n",
       " ('coin,', 2),\n",
       " ('coinage', 2),\n",
       " ('commencement', 2),\n",
       " ('conclusion,', 2),\n",
       " ('conjoined,', 2),\n",
       " ('convenient', 2),\n",
       " ('convex', 2),\n",
       " ('country,', 2),\n",
       " ('crescents', 2),\n",
       " ('cross;', 2),\n",
       " ('crosses', 2),\n",
       " ('curved', 2),\n",
       " ('date', 2),\n",
       " ('derived', 2),\n",
       " ('design', 2),\n",
       " ('device,', 2),\n",
       " ('devices,', 2),\n",
       " ('diademed', 2),\n",
       " ('died', 2),\n",
       " ('divided', 2),\n",
       " ('doubtful.', 2),\n",
       " ('draped', 2),\n",
       " ('eBook', 2),\n",
       " ('every', 2),\n",
       " ('evidence', 2),\n",
       " ('evident', 2),\n",
       " ('example', 2),\n",
       " ('example.', 2),\n",
       " ('extent', 2),\n",
       " ('facing', 2),\n",
       " ('field;', 2),\n",
       " ('figure,', 2),\n",
       " ('fixed', 2),\n",
       " ('following', 2),\n",
       " ('formed', 2),\n",
       " ('galloping,', 2),\n",
       " ('given', 2),\n",
       " ('greater', 2),\n",
       " ('having,', 2),\n",
       " ('heads', 2),\n",
       " ('higher', 2),\n",
       " ('horse.', 2),\n",
       " ('horseman,', 2),\n",
       " ('imitated', 2),\n",
       " ('indeed', 2),\n",
       " ('indications,', 2),\n",
       " ('inhabitants', 2),\n",
       " ('inhabited', 2),\n",
       " ('inland', 2),\n",
       " ('island', 2),\n",
       " ('it,', 2),\n",
       " ('kind', 2),\n",
       " ('king,', 2),\n",
       " ('kings.', 2),\n",
       " ('last', 2),\n",
       " ('last,', 2),\n",
       " ('later', 2),\n",
       " ('latter', 2),\n",
       " ('left,', 2),\n",
       " ('letters,', 2),\n",
       " ('letters.', 2),\n",
       " ('line', 2),\n",
       " ('located', 2),\n",
       " ('long', 2),\n",
       " ('marks', 2),\n",
       " ('matter', 2),\n",
       " ('minor', 2),\n",
       " ('mints', 2),\n",
       " ('moneyers', 2),\n",
       " ('mounted', 2),\n",
       " ('my', 2),\n",
       " ('name;', 2),\n",
       " ('national', 2),\n",
       " ('naturally', 2),\n",
       " ('none', 2),\n",
       " ('northern', 2),\n",
       " ('nothing', 2),\n",
       " ('now,', 2),\n",
       " ('numerous', 2),\n",
       " ('object', 2),\n",
       " ('object;', 2),\n",
       " ('oblong', 2),\n",
       " ('occasionally', 2),\n",
       " ('occurs', 2),\n",
       " ('one,', 2),\n",
       " ('opinion', 2),\n",
       " ('order', 2),\n",
       " ('originally', 2),\n",
       " ('ornament,', 2),\n",
       " ('ornament;', 2),\n",
       " ('ornaments;', 2),\n",
       " ('other;', 2),\n",
       " ('out', 2),\n",
       " ('outwards,', 2),\n",
       " ('partaking', 2),\n",
       " ('pellets', 2),\n",
       " ('place,', 2),\n",
       " ('points', 2),\n",
       " ('portion', 2),\n",
       " ('portions', 2),\n",
       " ('possible', 2),\n",
       " ('probability', 2),\n",
       " ('produced', 2),\n",
       " ('range', 2),\n",
       " ('reason,', 2),\n",
       " ('received', 2),\n",
       " ('reverse,', 2),\n",
       " ('ring,', 2),\n",
       " ('rule,', 2),\n",
       " ('satisfactorily', 2),\n",
       " ('say', 2),\n",
       " ('seated', 2),\n",
       " ('seven', 2),\n",
       " ('she', 2),\n",
       " ('shield,', 2),\n",
       " ('should', 2),\n",
       " ('simply', 2),\n",
       " ('single', 2),\n",
       " ('singular', 2),\n",
       " ('standing', 2),\n",
       " ('star', 2),\n",
       " ('step', 2),\n",
       " ('study', 2),\n",
       " ('taken', 2),\n",
       " ('them,', 2),\n",
       " ('third', 2),\n",
       " ('three,', 2),\n",
       " ('through', 2),\n",
       " ('to;', 2),\n",
       " ('tolerably', 2),\n",
       " ('torque', 2),\n",
       " ('tribe,', 2),\n",
       " ('true', 2),\n",
       " ('types.', 2),\n",
       " ('undraped', 2),\n",
       " ('unknown.', 2),\n",
       " ('usual', 2),\n",
       " ('where', 2),\n",
       " ('whole', 2),\n",
       " ('will', 2),\n",
       " ('would', 2),\n",
       " ('wreath', 2),\n",
       " ('written', 2),\n",
       " ('you', 2),\n",
       " ('ÆTHELSTAN', 2),\n",
       " ('Æthelstan', 2),\n",
       " ('“The', 2),\n",
       " ('“finds”', 2),\n",
       " ('#51302]', 1),\n",
       " ('&', 1),\n",
       " ('(924-940),', 1),\n",
       " ('(?),', 1),\n",
       " ('(Colchester)', 1),\n",
       " ('(Marseilles),', 1),\n",
       " ('(This', 1),\n",
       " ('(already', 1),\n",
       " ('(or', 1),\n",
       " ('(placed', 1),\n",
       " ('(possibly', 1),\n",
       " ('(probably', 1),\n",
       " ('(said', 1),\n",
       " ('(say', 1),\n",
       " ('(which', 1),\n",
       " ('150', 1),\n",
       " ('1770', 1),\n",
       " ('1886.', 1),\n",
       " ('2016', 1),\n",
       " ('240th', 1),\n",
       " ('26,', 1),\n",
       " ('30', 1),\n",
       " ('356,', 1),\n",
       " ('40', 1),\n",
       " ('41', 1),\n",
       " ('45', 1),\n",
       " ('5),', 1),\n",
       " ('55', 1),\n",
       " ('5760', 1),\n",
       " ('59', 1),\n",
       " ('600,', 1),\n",
       " ('670-685.', 1),\n",
       " ('685-705.', 1),\n",
       " ('688.', 1),\n",
       " ('725-764.', 1),\n",
       " ('737-758.', 1),\n",
       " ('757', 1),\n",
       " ('757-796.', 1),\n",
       " ('759-765.', 1),\n",
       " ('765-791.', 1),\n",
       " ('794-798.', 1),\n",
       " ('794-818.', 1),\n",
       " ('796.', 1),\n",
       " ('798-805.', 1),\n",
       " ('805-823.', 1),\n",
       " ('819-827.', 1),\n",
       " ('819.', 1),\n",
       " ('820-824.', 1),\n",
       " ('824,', 1),\n",
       " ('825-839.', 1),\n",
       " ('825.', 1),\n",
       " ('828-837.', 1),\n",
       " ('837-850.', 1),\n",
       " ('839-852.', 1),\n",
       " ('852-874.', 1),\n",
       " ('852.', 1),\n",
       " ('855-870.', 1),\n",
       " ('857', 1),\n",
       " ('870-890.', 1),\n",
       " ('874.', 1),\n",
       " ('A-J,', 1),\n",
       " ('ACSV', 1),\n",
       " ('ADDEDO,', 1),\n",
       " ('ADDEDO-MARVS,', 1),\n",
       " ('ADDEDOMAROS.', 1),\n",
       " ('ADDEDOMARVS,', 1),\n",
       " ('ADMVND;', 1),\n",
       " ('AESV,', 1),\n",
       " ('AETHELVVEARD,', 1),\n",
       " ('ALDFRID,', 1),\n",
       " ('ALDFRIDVS.', 1),\n",
       " ('AM,', 1),\n",
       " ('AM.', 1),\n",
       " ('AM;', 1),\n",
       " ('AMMI;', 1),\n",
       " ('AMMINVS', 1),\n",
       " ('ANCALITES,', 1),\n",
       " ('ANDO;', 1),\n",
       " ('ANDOC,', 1),\n",
       " ('ANG.', 1),\n",
       " ('ANGLES._', 1),\n",
       " ('ANGLO-SAXONS.', 1),\n",
       " ('ANTD', 1),\n",
       " ('ANTED', 1),\n",
       " ('ANTEDRIGV,', 1),\n",
       " ('ANTEDRIGVS', 1),\n",
       " ('ANTEDRIGVS.', 1),\n",
       " ('ANTE[BO]', 1),\n",
       " ('ANTE[BO],', 1),\n",
       " ('ANTE[BO]RI,', 1),\n",
       " ('ATHBADIV.', 1),\n",
       " ('ATREBATES,', 1),\n",
       " ('ATTACOTTI,', 1),\n",
       " ('AVN-T,', 1),\n",
       " ('AVNT', 1),\n",
       " ('A[BO][BO]IIDO[M],', 1),\n",
       " ('According', 1),\n",
       " ('Albans,', 1),\n",
       " ('Alfred.', 1),\n",
       " ('Anglesea.', 1),\n",
       " ('Antiquities;”', 1),\n",
       " ('Apollo,', 1),\n",
       " ('Archive)', 1),\n",
       " ('Archæological', 1),\n",
       " ('Art', 1),\n",
       " ('Ascertained', 1),\n",
       " ('Atrebatii,', 1),\n",
       " ('Augusti.', 1),\n",
       " ('Augustus', 1),\n",
       " ('Augustus,', 1),\n",
       " ('Author:', 1),\n",
       " ('B', 1),\n",
       " ('B);', 1),\n",
       " ('B.', 1),\n",
       " ('BARCLAY', 1),\n",
       " ('BAS', 1),\n",
       " ('BEALDRED', 1),\n",
       " ('BELDRED,', 1),\n",
       " ('BELGÆ,', 1),\n",
       " ('BEONNA', 1),\n",
       " ('BEONNA.', 1),\n",
       " ('BEORCHTRIC,', 1),\n",
       " ('BEORMIRIC,', 1),\n",
       " ('BEORNVVLF', 1),\n",
       " ('BEORNVVLF,', 1),\n",
       " ('BEORNWVLF', 1),\n",
       " ('BERHTVLF', 1),\n",
       " ('BERHTVVLF', 1),\n",
       " ('BERTHVVLF,', 1),\n",
       " ('BIBROCI,', 1),\n",
       " ('BODVO', 1),\n",
       " ('BODVO,', 1),\n",
       " ('BODVOC,', 1),\n",
       " ('BODVOC.', 1),\n",
       " ('BRIGANTES,', 1),\n",
       " ('BRIGANTES.', 1),\n",
       " ('BRITISH', 1),\n",
       " ('BRITONS.', 1),\n",
       " ('BURGHRED,', 1),\n",
       " ('BVRGRD;', 1),\n",
       " ('BVRGRED', 1),\n",
       " ('Beds.,', 1),\n",
       " ('Belgic', 1),\n",
       " ('Belgæ,', 1),\n",
       " ('Beonna', 1),\n",
       " ('Beorn', 1),\n",
       " ('Besides', 1),\n",
       " ('Bibroci.', 1),\n",
       " ('Boadicea.', 1),\n",
       " ('Brecknockshire,', 1),\n",
       " ('Bristol', 1),\n",
       " ('Bristol,', 1),\n",
       " ('Britain', 1),\n",
       " ('Britain;”', 1),\n",
       " ('Briton,', 1),\n",
       " ('Buckingham,', 1),\n",
       " ('C).', 1),\n",
       " ('CALLE', 1),\n",
       " ('CAM', 1),\n",
       " ('CAMV.', 1),\n",
       " ('CAMVL', 1),\n",
       " ('CANGI,', 1),\n",
       " ('CANTII,', 1),\n",
       " ('CASSI,', 1),\n",
       " ('CATTI', 1),\n",
       " ('CATYEUCHLANI,', 1),\n",
       " ('CENTRAL', 1),\n",
       " ('CHANNEL', 1),\n",
       " ('CIMBRI,', 1),\n",
       " ('CITS', 1),\n",
       " ('CN', 1),\n",
       " ('CO', 1),\n",
       " ('COENVVLF', 1),\n",
       " ('COENVVLF,', 1),\n",
       " ('COINS.]', 1),\n",
       " ('COM,', 1),\n",
       " ('COMVX', 1),\n",
       " ('COM·F,', 1),\n",
       " ('COM·F;', 1),\n",
       " ('CORF,', 1),\n",
       " ('CORF.', 1),\n",
       " ('CORITANI,', 1),\n",
       " ('CORITAVI,', 1),\n",
       " ('CORNABII,', 1),\n",
       " ('CO·F,', 1),\n",
       " ('CRAB', 1),\n",
       " ('CRAB.', 1),\n",
       " ('CROWN,”', 1),\n",
       " ('CUTHRED,', 1),\n",
       " ('CVN', 1),\n",
       " ('CVNOB.', 1),\n",
       " ('CVNOBELIN.', 1),\n",
       " ('CVNOBII.', 1),\n",
       " ('CYNEFRYTH.', 1),\n",
       " ('Caermarthenshire,', 1),\n",
       " ('Caernarvon,', 1),\n",
       " ('Calleva--Silchester--as', 1),\n",
       " ('Cambridgeshire', 1),\n",
       " ('Cambs.,', 1),\n",
       " ('Camulodunum', 1),\n",
       " ('Cantii,', 1),\n",
       " ('Capricorn,', 1),\n",
       " ('Caractacus', 1),\n",
       " ('Cardiganshire,', 1),\n",
       " ('Catyeuchlani', 1),\n",
       " ('Catyeuchlani,', 1),\n",
       " ('Ceolnoth.', 1),\n",
       " ('Ceolvvlf', 1),\n",
       " ('Ceramic', 1),\n",
       " ('Channel', 1),\n",
       " ('Channel,', 1),\n",
       " ('Character', 1),\n",
       " ('Cheshire,', 1),\n",
       " ('Chichester', 1),\n",
       " ('Chris', 1),\n",
       " ('Christ.', 1),\n",
       " ('Christian', 1),\n",
       " ('Ciolwulf.', 1),\n",
       " ('Civitas_', 1),\n",
       " ('Commius,', 1),\n",
       " ('Contents;”', 1),\n",
       " ('Cornwall', 1),\n",
       " ('Cornwall,', 1),\n",
       " ('Corresponding', 1),\n",
       " ('Council', 1),\n",
       " ('Crenides', 1),\n",
       " ('Cuerdale,', 1),\n",
       " ('Cumberland', 1),\n",
       " ('Cumberland.', 1),\n",
       " ('Cunobeline', 1),\n",
       " ('Cunobelinus', 1),\n",
       " ('Cunobelinus.', 1),\n",
       " ('Cæsar,', 1),\n",
       " ('Cæsar’s', 1),\n",
       " ('CŒNIMAGNI,', 1),\n",
       " ('DAMNONII,', 1),\n",
       " ('DEMETÆ,', 1),\n",
       " ('DIAS', 1),\n",
       " ('DIORMOD', 1),\n",
       " ('DOBUNI,', 1),\n",
       " ('DRVR', 1),\n",
       " ('DUMNONII,', 1),\n",
       " ('DUROTRIGES,', 1),\n",
       " ('DV;', 1),\n",
       " ('DVBN', 1),\n",
       " ('DVBNO', 1),\n",
       " ('DVBNO;', 1),\n",
       " ('DVBNOVELLAVNVS', 1),\n",
       " ('DVBNOVELLAVNVS.', 1),\n",
       " ('DVBNOVIILLA,', 1),\n",
       " ('DVBNO[VELLA]VNOS;', 1),\n",
       " ('DVM', 1),\n",
       " ('DVMN', 1),\n",
       " ('DVMN--TIGIP--SENO', 1),\n",
       " ('DVMNO', 1),\n",
       " ('DVMNOCOVEROS.', 1),\n",
       " ('DVMNOVERO;', 1),\n",
       " ('DVN', 1),\n",
       " ('DVRO-CAM[BORICVM]),', 1),\n",
       " ('Date:', 1),\n",
       " ('Denbigh,', 1),\n",
       " ('Derby,', 1),\n",
       " ('Devonshire,', 1),\n",
       " ('Distributed', 1),\n",
       " ('Dobuni,', 1),\n",
       " ('Dorset,', 1),\n",
       " ('E);', 1),\n",
       " ('EADBEARHT', 1),\n",
       " ('EADBEARHT,', 1),\n",
       " ('EADBERHT,', 1),\n",
       " ('EADMVND', 1),\n",
       " ('EADVALD', 1),\n",
       " ('EADVALD,', 1),\n",
       " ('EAST', 1),\n",
       " ('EASTERN', 1),\n",
       " ('EBOOK', 1),\n",
       " ('EBook', 1),\n",
       " ('ECGFRID', 1),\n",
       " ('ECGFRITH,', 1),\n",
       " ('EDELSTAN,', 1),\n",
       " ('EDELSTIN,', 1),\n",
       " ('EDILARE,', 1),\n",
       " ('EDI[L]HD[L]V,', 1),\n",
       " ('EGCBERHT', 1),\n",
       " ('EGCBERHT,', 1),\n",
       " ('EI', 1),\n",
       " ('EP.', 1),\n",
       " ('EP;', 1),\n",
       " ('EPAT.', 1),\n",
       " ('EPATI', 1),\n",
       " ('EPATICCV;', 1),\n",
       " ('EPATICCVS.', 1),\n",
       " ('EPATICVS', 1),\n",
       " ('EPP,', 1),\n",
       " ('EPP;', 1),\n",
       " ('EPPIL', 1),\n",
       " ('EPPIL,', 1),\n",
       " ('EPPILLUS.', 1),\n",
       " ('EPPILLVS', 1),\n",
       " ('ETA', 1),\n",
       " ('ETC.,', 1),\n",
       " ('ETHELOARO,', 1),\n",
       " ('ETHELTTAN', 1),\n",
       " ('ETHELVVEARD,', 1),\n",
       " ('ETHELZTAN', 1),\n",
       " ('ETHILWALD,', 1),\n",
       " ('Eadmund.', 1),\n",
       " ('Eadwerd.', 1),\n",
       " ('East', 1),\n",
       " ('Ecgberht.', 1),\n",
       " ('England,”', 1),\n",
       " ('Eppillus),', 1),\n",
       " ('Eppillus.', 1),\n",
       " ('Essex,', 1),\n",
       " ('Essex.', 1),\n",
       " ('Essex;', 1),\n",
       " ('Evans’s', 1),\n",
       " ('Evesham,', 1),\n",
       " ('Exeter,', 1),\n",
       " ('F.S.A.,', 1),\n",
       " ('FIL.', 1),\n",
       " ('F[IL]', 1),\n",
       " ('February', 1),\n",
       " ('First', 1),\n",
       " ('Flint,', 1),\n",
       " ('Flintshire.', 1),\n",
       " ('Forth.', 1),\n",
       " ('GADENI,', 1),\n",
       " ('GUTENBERG', 1),\n",
       " ('Gaul;', 1),\n",
       " ('Gauls', 1),\n",
       " ('German', 1),\n",
       " ('Glamorganshire.', 1),\n",
       " ('Gloucester;', 1),\n",
       " ('Gloucestershire.', 1),\n",
       " ('H);', 1),\n",
       " ('HEAD,', 1),\n",
       " ('HEDUI,', 1),\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('book.txt', 'r') as fi:\n",
    "    lines = [(i,line.strip()) for i,line in enumerate(fi) if i<1000]\n",
    "lines\n",
    "### After this, 'lines' stores a list of 1000 text lines\n",
    "def mapper(_, line):\n",
    "    for word in line.strip().split(' '):\n",
    "        if len(word)>0:\n",
    "            yield (word, 1)\n",
    "    \n",
    "def reducer(word, counts):\n",
    "    yield (word, sum(counts))\n",
    "\n",
    "wCounts = list(mr.run(lines, mapper, reducer))\n",
    "sortedCounts = sorted(wCounts, key=lambda x: -x[1])\n",
    "sortedCounts#[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Task 1 to Task 4, we re-do some tasks from Lab 3 (HOF) to familiarize ourselves with MapReduce\n",
    "\n",
    "## Task 1\n",
    "\n",
    "We would like to write a MapReduce job to count the total number of trips involved at each station. For example, if a trip starts at station A and stops at station B, the trip will count for both A and B. The output must be tuples, each consisting of a station name and a count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1 Ave & E 15 St', 795),\n",
       " ('1 Ave & E 44 St', 219),\n",
       " ('10 Ave & W 28 St', 422),\n",
       " ('11 Ave & W 27 St', 354),\n",
       " ('11 Ave & W 41 St', 461),\n",
       " ('11 Ave & W 59 St', 242),\n",
       " ('12 Ave & W 40 St', 217),\n",
       " ('2 Ave & E 31 St', 588),\n",
       " ('2 Ave & E 58 St', 125),\n",
       " ('3 Ave & Schermerhorn St', 34)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper1(_, row):\n",
    "    yield (row['start_station_name'], 1)\n",
    "    yield (row['end_station_name'], 1)\n",
    "\n",
    "def reducer1(station, counts):\n",
    "    yield (station, sum(counts))\n",
    "    \n",
    "with open('citibike.csv', 'r') as fi:\n",
    "    reader = enumerate(csv.DictReader(fi))\n",
    "    output1 = list(mr.run(reader, mapper1, reducer1))\n",
    "\n",
    "output1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2\n",
    "\n",
    "Below is an example of showing how to use nested jobs and jobs with mappers only using the mapreduce package, thus, no points are included. Our task here is that we would like to filter the output of Task 1 to display only those stations with more than 1000 trips involved, of course, using the MapReduce paradigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('8 Ave & W 31 St', 1065),\n",
       " ('E 43 St & Vanderbilt Ave', 1003),\n",
       " ('Lafayette St & E 8 St', 1013),\n",
       " ('W 21 St & 6 Ave', 1057),\n",
       " ('W 41 St & 8 Ave', 1095)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper2(station, count):\n",
    "    if count>1000:\n",
    "        yield (station, count)\n",
    "\n",
    "with open('citibike.csv', 'r') as fi:\n",
    "    reader = enumerate(csv.DictReader(fi))\n",
    "    output2 = list(mr.run(mr.run(reader, mapper1, reducer1), mapper2))\n",
    "\n",
    "output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3\n",
    "\n",
    "We would like to count the number of trips taken between pairs of stations. Trips taken from station A to station B or  from station B to station A are both counted towards the station pair A and B. Please note that the station pair shoud be identified by station names, as a tuple, and in lexical order, i.e. (A,B) instead of (B,A) in this case. The output must be tuples, each consisting of the station pair identification and a count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['1 Ave & E 15 St', '1 Ave & E 15 St'], 5),\n",
       " (['1 Ave & E 15 St', '1 Ave & E 44 St'], 6),\n",
       " (['1 Ave & E 15 St', '11 Ave & W 27 St'], 1),\n",
       " (['1 Ave & E 15 St', '2 Ave & E 31 St'], 9),\n",
       " (['1 Ave & E 15 St', '5 Ave & E 29 St'], 2),\n",
       " (['1 Ave & E 15 St', '6 Ave & Broome St'], 3),\n",
       " (['1 Ave & E 15 St', '6 Ave & Canal St'], 1),\n",
       " (['1 Ave & E 15 St', '8 Ave & W 31 St'], 5),\n",
       " (['1 Ave & E 15 St', '9 Ave & W 14 St'], 3),\n",
       " (['1 Ave & E 15 St', '9 Ave & W 16 St'], 3)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper3(_, row):\n",
    "    station = sorted([row['start_station_name'], row['end_station_name']])\n",
    "    yield (station, 1)\n",
    "\n",
    "def reducer3(station_pair, counts):\n",
    "    yield (station_pair, sum(counts))\n",
    "\n",
    "with open('citibike.csv', 'r') as fi:\n",
    "    reader = enumerate(csv.DictReader(fi))\n",
    "    output3 = list(mr.run(reader, mapper3, reducer3))\n",
    "\n",
    "output3[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 4\n",
    "\n",
    "In this task, you are asked to compute the station with the most riders started from, per each gender of the *'Subscriber'* user. Meaning, what was the station name with the highest number of bike pickups for female riders, for male riders and for unknown riders.\n",
    "\n",
    "The output will be a list of tuples, each includes a gender label (as indicated below) and another tuple consisting of a station name, and the total number of trips started at that station for that gender.\n",
    "\n",
    "The label mapping for the gender column in citibike.csv is: (Zero=<b>Unknown</b>; 1=<b>Male</b>; 2=<b>Female</b>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Unknown', ('Catherine St & Monroe St', 1)),\n",
       " ('Male', ('8 Ave & W 31 St', 488)),\n",
       " ('Female', ('W 21 St & 6 Ave', 107))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper4(_, row):\n",
    "    if row['usertype'] == \"Subscriber\":\n",
    "        yield ((row['gender'], row['start_station_name']), 1)\n",
    "\n",
    "\n",
    "def reducer4(gender_station, counts):\n",
    "    yield (gender_station, sum(counts))\n",
    "    \n",
    "    \n",
    "def mapper5(gender_station, counts):\n",
    "    gender, station = gender_station\n",
    "    yield (gender, (station, counts))\n",
    "    \n",
    "    \n",
    "def reducer5(gender, station_counts):\n",
    "    max_station_count = max(station_counts, key=lambda x:x[1])\n",
    "    label = (\"Unknown\", \"Male\", \"Female\")\n",
    "    yield (label[int(gender)], max_station_count)\n",
    "\n",
    "with open('citibike.csv', 'r') as fi:\n",
    "    reader = enumerate(csv.DictReader(fi))\n",
    "    output5 = list(mr.run(mr.run(reader, mapper4, reducer4), mapper5, reducer5))\n",
    "\n",
    "output5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 5\n",
    "\n",
    "We're going to tackle Task 3 of Homework 2 (or simply Homework 1) MapReduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('P02291', 16, 1181.9699999999998),\n",
       " ('P19498', 17, 989.99),\n",
       " ('P32565', 17, 1006.0899999999999),\n",
       " ('P33162', 18, 1210.9199999999998),\n",
       " ('P39328', 17, 1129.0099999999998),\n",
       " ('P58225', 17, 1349.8199999999997),\n",
       " ('P61235', 18, 959.0199999999999),\n",
       " ('P76615', 18, 1087.9599999999998),\n",
       " ('P82222', 17, 950.0500000000001),\n",
       " ('P92449', 14, 966.17)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper6(_, row):\n",
    "    yield ((row['Product ID'], row['Customer ID']), float(row['Item Cost']))\n",
    "    \n",
    "    \n",
    "def reducer6(pid_cid, costs):\n",
    "    pid, cid = pid_cid\n",
    "    yield (pid, sum(costs))\n",
    "    \n",
    "def mapper7(pid, cost):\n",
    "    yield (pid, cost)\n",
    "    \n",
    "def reducer7(pid, costs):\n",
    "    yield (pid, len(costs), sum(costs))    \n",
    "    \n",
    "    \n",
    "with open('sale.csv', 'r') as fi:\n",
    "    reader = enumerate(csv.DictReader(fi))\n",
    "    output3 = list(mr.run(mr.run(reader, mapper6, reducer6), mapper7, reducer7))\n",
    "\n",
    "output3[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 6\n",
    "\n",
    "MRJob is a convenient packages for simplifying the execution of MapReduce jobs on clusters. However, it doesn't work in a notebook. We're going to convert some of the examples of MRJob into our notebooks so that we can test our code before deploying them on Hadoop.\n",
    "\n",
    "The two examples are available at:\n",
    "https://pythonhosted.org/mrjob/guides/quickstart.html\n",
    "https://pythonhosted.org/mrjob/guides/writing-mrjobs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 419),\n",
       " ('of', 343),\n",
       " ('and', 260),\n",
       " ('a', 196),\n",
       " ('or', 163),\n",
       " ('to', 104),\n",
       " ('with', 103),\n",
       " ('in', 90),\n",
       " ('coins', 71),\n",
       " ('on', 69)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mrjob.job import MRJob\n",
    "import re\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "\n",
    "class MRWordFreqCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        for word in WORD_RE.findall(line):\n",
    "            yield word.lower(), 1\n",
    "\n",
    "    def combiner(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        yield word, sum(counts)\n",
    "\n",
    "\n",
    "with open('book.txt', 'r') as fi:\n",
    "    lines = [(i,line.strip()) for i,line in enumerate(fi) if i<1000]\n",
    "\n",
    "job = MRWordFreqCount()\n",
    "wCounts = list(mr.run(lines, job.mapper, job.reducer))\n",
    "sortedCounts = sorted(wCounts, key=lambda x: -x[1])\n",
    "sortedCounts[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 7\n",
    "\n",
    "Let's try to run the above MRJob examples as stand-alone applications. Please check again:\n",
    "https://pythonhosted.org/mrjob/guides/quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object combine.<locals>.<genexpr> at 0x7ff1e40fc8b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "import re\n",
    "\n",
    "WORD_RE = re.compile(r\"[\\w']+\")\n",
    "\n",
    "\n",
    "class MRMostUsedWord(MRJob):\n",
    "\n",
    "    def mapper_get_words(self, _, line):\n",
    "        # yield each word in the line\n",
    "        for word in WORD_RE.findall(line):\n",
    "            yield (word.lower(), 1)\n",
    "\n",
    "    def combiner_count_words(self, word, counts):\n",
    "        # sum the words we've seen so far\n",
    "        yield (word, sum(counts))\n",
    "\n",
    "    def reducer_count_words(self, word, counts):\n",
    "        # send all (num_occurrences, word) pairs to the same reducer.\n",
    "        # num_occurrences is so we can easily use Python's max() function.\n",
    "        yield None, (sum(counts), word)\n",
    "\n",
    "    # discard the key; it is just None\n",
    "    def reducer_find_max_word(self, _, word_count_pairs):\n",
    "        # each item of word_count_pairs is (count, word),\n",
    "        # so yielding one results in key=counts, value=word\n",
    "        yield max(word_count_pairs)\n",
    "\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_get_words,\n",
    "                   combiner=self.combiner_count_words,\n",
    "                   reducer=self.reducer_count_words),\n",
    "            MRStep(reducer=self.reducer_find_max_word)\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "job = MRMostUsedWord()\n",
    "wCounts = mr.run(lines, job)\n",
    "wCounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gender' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-27af69a49e3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Male\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Female\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_station_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gender' is not defined"
     ]
    }
   ],
   "source": [
    "label = (\"Unknown\", \"Male\", \"Female\")\n",
    "(label[int(gender)], max_station_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
